2023-04-12 18:56:00 [INFO] [task_scheduler.cc:160] Initializing Task #45: "fused_nn_max_pool2d"
2023-04-12 18:56:00 [INFO] [task_scheduler.cc:35] 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(T.int64(1), T.int64(64), T.int64(112), T.int64(112)), "float32"], pool_max: T.Buffer[(T.int64(1), T.int64(64), T.int64(56), T.int64(56)), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        pad_temp = T.alloc_buffer([T.int64(1), T.int64(64), T.int64(113), T.int64(113)], dtype="float32")
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(64), T.int64(113), T.int64(113)):
            with T.block("pad_temp"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(p0[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(pad_temp[v_ax0, v_ax1, v_ax2, v_ax3])
                pad_temp[v_ax0, v_ax1, v_ax2, v_ax3] = T.if_then_else(v_ax2 < T.int64(112) and v_ax3 < T.int64(112), p0[v_ax0, v_ax1, v_ax2, v_ax3], T.float32(-3.4028234663852886e+38), dtype="float32")
        for ax0, ax1, ax2, ax3, rv0, rv1 in T.grid(T.int64(1), T.int64(64), T.int64(56), T.int64(56), T.int64(3), T.int64(3)):
            with T.block("pool_max"):
                v_ax0, v_ax1, v_ax2, v_ax3, v_rv0, v_rv1 = T.axis.remap("SSSSRR", [ax0, ax1, ax2, ax3, rv0, rv1])
                T.reads(pad_temp[v_ax0, v_ax1, v_ax2 * T.int64(2) + v_rv0, v_ax3 * T.int64(2) + v_rv1])
                T.writes(pool_max[v_ax0, v_ax1, v_ax2, v_ax3])
                T.block_attr({"schedule_rule":"meta_schedule.pool_max"})
                with T.init():
                    pool_max[v_ax0, v_ax1, v_ax2, v_ax3] = T.float32(-3.4028234663852886e+38)
                pool_max[v_ax0, v_ax1, v_ax2, v_ax3] = T.max(pool_max[v_ax0, v_ax1, v_ax2, v_ax3], pad_temp[v_ax0, v_ax1, v_ax2 * T.int64(2) + v_rv0, v_ax3 * T.int64(2) + v_rv1])
    

2023-04-12 18:56:00 [INFO] [task_scheduler.cc:164] Total 2 design space(s) generated
2023-04-12 18:56:00 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(T.int64(1), T.int64(64), T.int64(112), T.int64(112)), "float32"], pool_max: T.Buffer[(T.int64(1), T.int64(64), T.int64(56), T.int64(56)), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":0})
            for ax0_ax1_ax2_ax3_fused_0 in T.thread_binding(T.int64(784), thread="blockIdx.x"):
                for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    for rv0, rv1 in T.grid(T.int64(3), T.int64(3)):
                        with T.block("pool_max"):
                            v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                            v_ax1 = T.axis.spatial(T.int64(64), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) // T.int64(3136))
                            v_ax2 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(3136) // T.int64(56))
                            v_ax3 = T.axis.spatial(T.int64(56), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1) % T.int64(56))
                            v_rv0, v_rv1 = T.axis.remap("RR", [rv0, rv1])
                            T.reads(p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + v_rv0, v_ax3 * T.int64(2) + v_rv1])
                            T.writes(pool_max[v_ax0, v_ax1, v_ax2, v_ax3])
                            with T.init():
                                pool_max[v_ax0, v_ax1, v_ax2, v_ax3] = T.float32(-3.4028234663852886e+38)
                            pool_max[v_ax0, v_ax1, v_ax2, v_ax3] = T.max(pool_max[v_ax0, v_ax1, v_ax2, v_ax3], T.if_then_else(v_ax2 * T.int64(2) + v_rv0 < T.int64(112) and v_ax3 * T.int64(2) + v_rv1 < T.int64(112), p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + v_rv0, v_ax3 * T.int64(2) + v_rv1], T.float32(-3.4028234663852886e+38), dtype="float32"))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="pool_max", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b1, ann_key="schedule_rule")
sch.compute_inline(block=b0)
v3 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v3)
l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
l10 = sch.fuse(l4, l5, l6, l7, preserve_unit_iters=True)
v11 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l12, l13 = sch.split(loop=l10, factors=[None, v11], preserve_unit_iters=True)
sch.bind(loop=l12, thread_axis="blockIdx.x")
sch.bind(loop=l13, thread_axis="threadIdx.x")
2023-04-12 18:56:00 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(T.int64(1), T.int64(64), T.int64(112), T.int64(112)), "float32"], pool_max: T.Buffer[(T.int64(1), T.int64(64), T.int64(56), T.int64(56)), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":512})
            for ax0_ax1_ax2_ax3_fused in T.thread_binding(T.int64(200704), thread="blockIdx.x"):
                for rv0_rv1_fused_0 in T.serial(T.int64(1)):
                    for rv0_rv1_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                        with T.block("pool_max"):
                            T.where(rv0_rv1_fused_0 * T.int64(512) + rv0_rv1_fused_1 < T.int64(9))
                            v_ax0 = T.axis.spatial(T.int64(1), T.int64(0))
                            v_ax1 = T.axis.spatial(T.int64(64), ax0_ax1_ax2_ax3_fused // T.int64(3136))
                            v_ax2 = T.axis.spatial(T.int64(56), ax0_ax1_ax2_ax3_fused % T.int64(3136) // T.int64(56))
                            v_ax3 = T.axis.spatial(T.int64(56), ax0_ax1_ax2_ax3_fused % T.int64(56))
                            v_rv0 = T.axis.reduce(T.int64(3), (rv0_rv1_fused_0 * T.int64(512) + rv0_rv1_fused_1) // T.int64(3))
                            v_rv1 = T.axis.reduce(T.int64(3), (rv0_rv1_fused_0 * T.int64(512) + rv0_rv1_fused_1) % T.int64(3))
                            T.reads(p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + v_rv0, v_ax3 * T.int64(2) + v_rv1])
                            T.writes(pool_max[v_ax0, v_ax1, v_ax2, v_ax3])
                            with T.init():
                                pool_max[v_ax0, v_ax1, v_ax2, v_ax3] = T.float32(-3.4028234663852886e+38)
                            pool_max[v_ax0, v_ax1, v_ax2, v_ax3] = T.max(pool_max[v_ax0, v_ax1, v_ax2, v_ax3], T.if_then_else(v_ax2 * T.int64(2) + v_rv0 < T.int64(112) and v_ax3 * T.int64(2) + v_rv1 < T.int64(112), p0[v_ax0, v_ax1, v_ax2 * T.int64(2) + v_rv0, v_ax3 * T.int64(2) + v_rv1], T.float32(-3.4028234663852886e+38), dtype="float32"))
    

b0 = sch.get_block(name="pad_temp", func_name="main")
b1 = sch.get_block(name="pool_max", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b1, ann_key="schedule_rule")
sch.compute_inline(block=b0)
v3 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=7)
l4, l5, l6, l7, l8, l9 = sch.get_loops(block=b1)
l10 = sch.fuse(l8, l9, preserve_unit_iters=True)
l11, l12 = sch.split(loop=l10, factors=[None, v3], preserve_unit_iters=True)
sch.bind(loop=l12, thread_axis="threadIdx.x")
v13 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v13)
l14, l15, l16, l17, l18, l19 = sch.get_loops(block=b1)
l20 = sch.fuse(l14, l15, l16, l17, preserve_unit_iters=True)
sch.bind(loop=l20, thread_axis="blockIdx.x")
2023-04-12 19:00:19 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-04-12 19:00:19 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2023-04-12 19:00:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564eef918538)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564eed841d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564eed841cf8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564eec2a1978)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564ef853ccc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564eed2eab08)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564eeae04008)]: 0 failure(s)
2023-04-12 19:00:20 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2023-04-12 19:00:21 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564eef918538)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564eed841d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564eed841cf8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564eec2a1978)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564ef853ccc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564eed2eab08)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564eeae04008)]: 0 failure(s)
2023-04-12 19:00:21 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564eef918538)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564eed841d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564eed841cf8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564eec2a1978)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564ef853ccc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564eed2eab08)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564eeae04008)]: 0 failure(s)
2023-04-12 19:00:21 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564eef918538)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564eed841d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564eed841cf8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564eec2a1978)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564ef853ccc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564eed2eab08)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564eeae04008)]: 0 failure(s)
2023-04-12 19:00:22 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564eef918538)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564eed841d28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564eed841cf8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564eec2a1978)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564ef853ccc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564eed2eab08)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564eeae04008)]: 0 failure(s)
2023-04-12 19:00:22 [INFO] [evolutionary_search.cc:649] Scores of the best 10 candidates:
[1 : 10]:	0.9962  0.9654  0.9554  0.9351  0.9300  0.9230  0.9021  0.9010  0.8994  0.8813
2023-04-12 19:00:22 [INFO] [evolutionary_search.cc:727] Got 10 candidate(s) with evolutionary search
2023-04-12 19:00:22 [INFO] [evolutionary_search.cc:730] Sending 10 candidates(s) for measurement
2023-04-12 19:03:30 [INFO] [task_scheduler.cc:131] [Task #45: fused_nn_max_pool2d] Trial #1: GFLOPs: 2.8907. Time: 624.8702 us. Best GFLOPs: 2.8907
2023-04-12 19:03:30 [INFO] [task_scheduler.cc:131] [Task #45: fused_nn_max_pool2d] Trial #2: GFLOPs: 11.8902. Time: 151.9176 us. Best GFLOPs: 11.8902
2023-04-12 19:03:30 [INFO] [task_scheduler.cc:131] [Task #45: fused_nn_max_pool2d] Trial #3: GFLOPs: 382.5073. Time: 4.7224 us. Best GFLOPs: 382.5073
2023-04-12 19:03:30 [INFO] [task_scheduler.cc:131] [Task #45: fused_nn_max_pool2d] Trial #4: GFLOPs: 11.8935. Time: 151.8759 us. Best GFLOPs: 382.5073
2023-04-12 19:03:30 [INFO] [task_scheduler.cc:131] [Task #45: fused_nn_max_pool2d] Trial #5: GFLOPs: 373.2182. Time: 4.8399 us. Best GFLOPs: 382.5073
2023-04-12 19:03:30 [INFO] [task_scheduler.cc:131] [Task #45: fused_nn_max_pool2d] Trial #6: GFLOPs: 373.3441. Time: 4.8383 us. Best GFLOPs: 382.5073
2023-04-12 19:03:30 [INFO] [task_scheduler.cc:131] [Task #45: fused_nn_max_pool2d] Trial #7: GFLOPs: 11.9035. Time: 151.7479 us. Best GFLOPs: 382.5073
2023-04-12 19:03:30 [INFO] [task_scheduler.cc:131] [Task #45: fused_nn_max_pool2d] Trial #8: GFLOPs: 11.8693. Time: 152.1862 us. Best GFLOPs: 382.5073
2023-04-12 19:03:30 [INFO] [task_scheduler.cc:131] [Task #45: fused_nn_max_pool2d] Trial #9: GFLOPs: 11.8939. Time: 151.8714 us. Best GFLOPs: 382.5073
2023-04-12 19:03:30 [INFO] [task_scheduler.cc:131] [Task #45: fused_nn_max_pool2d] Trial #10: GFLOPs: 11.8943. Time: 151.8652 us. Best GFLOPs: 382.5073
