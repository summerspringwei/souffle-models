2023-04-12 18:55:58 [INFO] [task_scheduler.cc:160] Initializing Task #34: "fused_add_rsqrt_multiply_6"
2023-04-12 18:55:58 [INFO] [task_scheduler.cc:35] 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[T.int64(256), "float32"], p1: T.Buffer[T.int64(256), "float32"], T_multiply: T.Buffer[T.int64(256), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_add = T.alloc_buffer([T.int64(256)], dtype="float32")
        tensor = T.alloc_buffer([T.int64(256)], dtype="float32")
        with T.block("compile_engine_const"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0.0010000000474974513)
        for ax0 in T.serial(T.int64(256)):
            with T.block("T_add"):
                v_ax0 = T.axis.spatial(T.int64(256), ax0)
                T.reads(p0[v_ax0], compile_engine_const[()])
                T.writes(T_add[v_ax0])
                T_add[v_ax0] = p0[v_ax0] + compile_engine_const[()]
        for ax0 in T.serial(T.int64(256)):
            with T.block("tensor"):
                v_ax0 = T.axis.spatial(T.int64(256), ax0)
                T.reads(T_add[v_ax0])
                T.writes(tensor[v_ax0])
                tensor[v_ax0] = T.float32(1) / T.sqrt(T_add[v_ax0], dtype="float32")
        for ax0 in T.serial(T.int64(256)):
            with T.block("T_multiply"):
                v_ax0 = T.axis.spatial(T.int64(256), ax0)
                T.reads(tensor[v_ax0], p1[v_ax0])
                T.writes(T_multiply[v_ax0])
                T_multiply[v_ax0] = tensor[v_ax0] * p1[v_ax0]
    

2023-04-12 18:55:58 [INFO] [task_scheduler.cc:164] Total 1 design space(s) generated
2023-04-12 18:55:58 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[T.int64(256), "float32"], p1: T.Buffer[T.int64(256), "float32"], T_multiply: T.Buffer[T.int64(256), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for ax0_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(256), ax0_fused_0 * T.int64(128) + ax0_fused_1)
                    T.reads(p0[v_ax0], p1[v_ax0])
                    T.writes(T_multiply[v_ax0])
                    T_multiply[v_ax0] = T.float32(1) / T.sqrt(p0[v_ax0] + T.float32(0.0010000000474974513), dtype="float32") * p1[v_ax0]
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="tensor", func_name="main")
b3 = sch.get_block(name="T_multiply", func_name="main")
sch.compute_inline(block=b0)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
l4, = sch.get_loops(block=b1)
l5 = sch.fuse(l4, preserve_unit_iters=True)
v6 = sch.sample_categorical(candidates=[32, 64, 128, 256], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
l7, l8 = sch.split(loop=l5, factors=[None, v6], preserve_unit_iters=True)
sch.bind(loop=l7, thread_axis="blockIdx.x")
sch.bind(loop=l8, thread_axis="threadIdx.x")
2023-04-12 18:59:25 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-04-12 18:59:25 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2023-04-12 18:59:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564eed77fb48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564ef08dc478)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564eec895b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564eeefb0738)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564efbc86bc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564eed43bd48)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564ef0b03858)]: 0 failure(s)
2023-04-12 18:59:25 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2023-04-12 18:59:25 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564eed77fb48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564ef08dc478)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564eec895b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564eeefb0738)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564efbc86bc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564eed43bd48)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564ef0b03858)]: 0 failure(s)
2023-04-12 18:59:25 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564eed77fb48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564ef08dc478)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564eec895b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564eeefb0738)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564efbc86bc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564eed43bd48)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564ef0b03858)]: 0 failure(s)
2023-04-12 18:59:25 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564eed77fb48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564ef08dc478)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564eec895b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564eeefb0738)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564efbc86bc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564eed43bd48)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564ef0b03858)]: 0 failure(s)
2023-04-12 18:59:25 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564eed77fb48)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564ef08dc478)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564eec895b68)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564eeefb0738)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564efbc86bc8)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564eed43bd48)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564ef0b03858)]: 0 failure(s)
2023-04-12 18:59:25 [INFO] [evolutionary_search.cc:649] Scores of the best 4 candidates:
[1 : 4]:	0.8629  0.5041  0.1743  0.1131
2023-04-12 18:59:25 [INFO] [evolutionary_search.cc:727] Got 4 candidate(s) with evolutionary search
2023-04-12 18:59:25 [INFO] [evolutionary_search.cc:730] Sending 4 candidates(s) for measurement
2023-04-12 19:03:29 [INFO] [task_scheduler.cc:131] [Task #34: fused_add_rsqrt_multiply_6] Trial #1: GFLOPs: 0.2620. Time: 2.9313 us. Best GFLOPs: 0.2620
2023-04-12 19:03:29 [INFO] [task_scheduler.cc:131] [Task #34: fused_add_rsqrt_multiply_6] Trial #2: GFLOPs: 0.2835. Time: 2.7087 us. Best GFLOPs: 0.2835
2023-04-12 19:03:29 [INFO] [task_scheduler.cc:131] [Task #34: fused_add_rsqrt_multiply_6] Trial #3: GFLOPs: 0.3322. Time: 2.3119 us. Best GFLOPs: 0.3322
2023-04-12 19:03:29 [INFO] [task_scheduler.cc:131] [Task #34: fused_add_rsqrt_multiply_6] Trial #4: GFLOPs: 0.2835. Time: 2.7086 us. Best GFLOPs: 0.3322
