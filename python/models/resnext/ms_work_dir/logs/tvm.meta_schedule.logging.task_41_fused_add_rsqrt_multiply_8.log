2023-04-12 18:55:59 [INFO] [task_scheduler.cc:160] Initializing Task #41: "fused_add_rsqrt_multiply_8"
2023-04-12 18:55:59 [INFO] [task_scheduler.cc:35] 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[T.int64(64), "float32"], p1: T.Buffer[T.int64(64), "float32"], T_multiply: T.Buffer[T.int64(64), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        compile_engine_const = T.alloc_buffer([], dtype="float32")
        T_add = T.alloc_buffer([T.int64(64)], dtype="float32")
        tensor = T.alloc_buffer([T.int64(64)], dtype="float32")
        with T.block("compile_engine_const"):
            vi = T.axis.spatial(T.int64(1), T.int64(0))
            T.reads()
            T.writes(compile_engine_const[()])
            compile_engine_const[()] = T.float32(0.0010000000474974513)
        for ax0 in T.serial(T.int64(64)):
            with T.block("T_add"):
                v_ax0 = T.axis.spatial(T.int64(64), ax0)
                T.reads(p0[v_ax0], compile_engine_const[()])
                T.writes(T_add[v_ax0])
                T_add[v_ax0] = p0[v_ax0] + compile_engine_const[()]
        for ax0 in T.serial(T.int64(64)):
            with T.block("tensor"):
                v_ax0 = T.axis.spatial(T.int64(64), ax0)
                T.reads(T_add[v_ax0])
                T.writes(tensor[v_ax0])
                tensor[v_ax0] = T.float32(1) / T.sqrt(T_add[v_ax0], dtype="float32")
        for ax0 in T.serial(T.int64(64)):
            with T.block("T_multiply"):
                v_ax0 = T.axis.spatial(T.int64(64), ax0)
                T.reads(tensor[v_ax0], p1[v_ax0])
                T.writes(T_multiply[v_ax0])
                T_multiply[v_ax0] = tensor[v_ax0] * p1[v_ax0]
    

2023-04-12 18:55:59 [INFO] [task_scheduler.cc:164] Total 1 design space(s) generated
2023-04-12 18:55:59 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[T.int64(64), "float32"], p1: T.Buffer[T.int64(64), "float32"], T_multiply: T.Buffer[T.int64(64), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        for ax0_fused_0 in T.thread_binding(T.int64(2), thread="blockIdx.x"):
            for ax0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                with T.block("T_add"):
                    v_ax0 = T.axis.spatial(T.int64(64), ax0_fused_0 * T.int64(32) + ax0_fused_1)
                    T.reads(p0[v_ax0], p1[v_ax0])
                    T.writes(T_multiply[v_ax0])
                    T_multiply[v_ax0] = T.float32(1) / T.sqrt(p0[v_ax0] + T.float32(0.0010000000474974513), dtype="float32") * p1[v_ax0]
    

b0 = sch.get_block(name="compile_engine_const", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="tensor", func_name="main")
b3 = sch.get_block(name="T_multiply", func_name="main")
sch.compute_inline(block=b0)
sch.reverse_compute_inline(block=b3)
sch.reverse_compute_inline(block=b2)
l4, = sch.get_loops(block=b1)
l5 = sch.fuse(l4, preserve_unit_iters=True)
v6 = sch.sample_categorical(candidates=[32, 64], probs=[0.5, 0.5], decision=0)
l7, l8 = sch.split(loop=l5, factors=[None, v6], preserve_unit_iters=True)
sch.bind(loop=l7, thread_axis="blockIdx.x")
sch.bind(loop=l8, thread_axis="threadIdx.x")
2023-04-12 18:59:48 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-04-12 18:59:48 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2023-04-12 18:59:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564eeae56508)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564ef8510b18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564ef8510ae8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564ef4d41638)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564ef018ab58)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564ef9471a88)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564eed8b6578)]: 0 failure(s)
2023-04-12 18:59:48 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2023-04-12 18:59:48 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564eeae56508)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564ef8510b18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564ef8510ae8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564ef4d41638)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564ef018ab58)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564ef9471a88)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564eed8b6578)]: 0 failure(s)
2023-04-12 18:59:48 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564eeae56508)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564ef8510b18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564ef8510ae8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564ef4d41638)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564ef018ab58)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564ef9471a88)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564eed8b6578)]: 0 failure(s)
2023-04-12 18:59:48 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564eeae56508)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564ef8510b18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564ef8510ae8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564ef4d41638)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564ef018ab58)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564ef9471a88)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564eed8b6578)]: 0 failure(s)
2023-04-12 18:59:48 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564eeae56508)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564ef8510b18)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564ef8510ae8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564ef4d41638)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564ef018ab58)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564ef9471a88)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564eed8b6578)]: 0 failure(s)
2023-04-12 18:59:48 [INFO] [evolutionary_search.cc:649] Scores of the best 2 candidates:
[1 : 2]:	0.5542  0.0179
2023-04-12 18:59:48 [INFO] [evolutionary_search.cc:727] Got 2 candidate(s) with evolutionary search
2023-04-12 18:59:48 [INFO] [evolutionary_search.cc:730] Sending 2 candidates(s) for measurement
2023-04-12 19:03:29 [INFO] [task_scheduler.cc:131] [Task #41: fused_add_rsqrt_multiply_8] Trial #1: GFLOPs: 0.0812. Time: 2.3643 us. Best GFLOPs: 0.0812
2023-04-12 19:03:29 [INFO] [task_scheduler.cc:131] [Task #41: fused_add_rsqrt_multiply_8] Trial #2: GFLOPs: 0.0655. Time: 2.9296 us. Best GFLOPs: 0.0812
