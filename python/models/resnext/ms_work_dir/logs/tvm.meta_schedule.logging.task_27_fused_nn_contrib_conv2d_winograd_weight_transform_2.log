2023-04-12 18:55:57 [INFO] [task_scheduler.cc:160] Initializing Task #27: "fused_nn_contrib_conv2d_winograd_weight_transform_2"
2023-04-12 18:55:57 [INFO] [task_scheduler.cc:35] 
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(T.int64(8), T.int64(8), T.int64(3), T.int64(3)), "float32"], transform_weight: T.Buffer[(T.int64(4), T.int64(4), T.int64(8), T.int64(8)), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        # with T.block("root")
        G = T.alloc_buffer([T.int64(4), T.int64(3)], dtype="float32")
        for i, j in T.grid(T.int64(4), T.int64(3)):
            with T.block("G"):
                v_i, v_j = T.axis.remap("SS", [i, j])
                T.reads()
                T.writes(G[v_i, v_j])
                T.block_attr({"schedule_rule":"None"})
                G[v_i, v_j] = T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(3) == T.int64(2), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(3) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(3) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(3) == T.int64(2), T.float32(0.5), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(3) == T.int64(1), T.float32(0.5), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(3) == T.int64(0), T.float32(0.5), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(3) == T.int64(2), T.float32(0.5), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(3) == T.int64(1), T.float32(-0.5), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(3) == T.int64(0), T.float32(0.5), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(3) == T.int64(2), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(3) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(3) == T.int64(0), T.float32(1), T.float32(0)))))))))))))
        for eps, nu, co, ci, r_kh, r_kw in T.grid(T.int64(4), T.int64(4), T.int64(8), T.int64(8), T.int64(3), T.int64(3)):
            with T.block("transform_weight"):
                v_eps, v_nu, v_co, v_ci, v_r_kh, v_r_kw = T.axis.remap("SSSSRR", [eps, nu, co, ci, r_kh, r_kw])
                T.reads(p0[v_co, v_ci, v_r_kh, v_r_kw], G[T.min(v_eps, v_nu) : T.max(v_eps, v_nu) + T.int64(1), T.min(v_r_kh, v_r_kw) : T.max(v_r_kh, v_r_kw) + T.int64(1)])
                T.writes(transform_weight[v_eps, v_nu, v_co, v_ci])
                with T.init():
                    transform_weight[v_eps, v_nu, v_co, v_ci] = T.float32(0)
                transform_weight[v_eps, v_nu, v_co, v_ci] = transform_weight[v_eps, v_nu, v_co, v_ci] + p0[v_co, v_ci, v_r_kh, v_r_kw] * G[v_eps, v_r_kh] * G[v_nu, v_r_kw]
    

2023-04-12 18:55:57 [INFO] [task_scheduler.cc:164] Total 2 design space(s) generated
2023-04-12 18:55:57 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(T.int64(8), T.int64(8), T.int64(3), T.int64(3)), "float32"], transform_weight: T.Buffer[(T.int64(4), T.int64(4), T.int64(8), T.int64(8)), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":0})
            G = T.alloc_buffer([T.int64(4), T.int64(3)], dtype="float32")
            for i, j in T.grid(T.int64(4), T.int64(3)):
                with T.block("G"):
                    v_i, v_j = T.axis.remap("SS", [i, j])
                    T.reads()
                    T.writes(G[v_i, v_j])
                    T.block_attr({"schedule_rule":"None"})
                    G[v_i, v_j] = T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(3) == T.int64(2), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(3) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(3) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(3) == T.int64(2), T.float32(0.5), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(3) == T.int64(1), T.float32(0.5), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(3) == T.int64(0), T.float32(0.5), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(3) == T.int64(2), T.float32(0.5), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(3) == T.int64(1), T.float32(-0.5), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(3) == T.int64(0), T.float32(0.5), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(3) == T.int64(2), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(3) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(3) == T.int64(0), T.float32(1), T.float32(0)))))))))))))
            for eps_nu_co_ci_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
                for eps_nu_co_ci_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for r_kh, r_kw in T.grid(T.int64(3), T.int64(3)):
                        with T.block("transform_weight"):
                            v_eps = T.axis.spatial(T.int64(4), (eps_nu_co_ci_fused_0 * T.int64(128) + eps_nu_co_ci_fused_1) // T.int64(256))
                            v_nu = T.axis.spatial(T.int64(4), (eps_nu_co_ci_fused_0 * T.int64(128) + eps_nu_co_ci_fused_1) % T.int64(256) // T.int64(64))
                            v_co = T.axis.spatial(T.int64(8), (eps_nu_co_ci_fused_0 * T.int64(128) + eps_nu_co_ci_fused_1) % T.int64(64) // T.int64(8))
                            v_ci = T.axis.spatial(T.int64(8), (eps_nu_co_ci_fused_0 * T.int64(128) + eps_nu_co_ci_fused_1) % T.int64(8))
                            v_r_kh, v_r_kw = T.axis.remap("RR", [r_kh, r_kw])
                            T.reads(p0[v_co, v_ci, v_r_kh, v_r_kw], G[T.min(v_eps, v_nu) : T.max(v_eps, v_nu) + T.int64(1), T.min(v_r_kh, v_r_kw) : T.max(v_r_kh, v_r_kw) + T.int64(1)])
                            T.writes(transform_weight[v_eps, v_nu, v_co, v_ci])
                            with T.init():
                                transform_weight[v_eps, v_nu, v_co, v_ci] = T.float32(0)
                            transform_weight[v_eps, v_nu, v_co, v_ci] = transform_weight[v_eps, v_nu, v_co, v_ci] + p0[v_co, v_ci, v_r_kh, v_r_kw] * G[v_eps, v_r_kh] * G[v_nu, v_r_kw]
    

b0 = sch.get_block(name="transform_weight", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
v2 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v2)
l3, l4, l5, l6, l7, l8 = sch.get_loops(block=b0)
l9 = sch.fuse(l3, l4, l5, l6, preserve_unit_iters=True)
v10 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l11, l12 = sch.split(loop=l9, factors=[None, v10], preserve_unit_iters=True)
sch.bind(loop=l11, thread_axis="blockIdx.x")
sch.bind(loop=l12, thread_axis="threadIdx.x")
2023-04-12 18:55:57 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import tir as T
@tvm.script.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer[(T.int64(8), T.int64(8), T.int64(3), T.int64(3)), "float32"], transform_weight: T.Buffer[(T.int64(4), T.int64(4), T.int64(8), T.int64(8)), "float32"]):
        # function attr dict
        T.func_attr({"global_symbol": "main", "tir.noalias": True})
        # body
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit":64})
            G = T.alloc_buffer([T.int64(4), T.int64(3)], dtype="float32")
            for i, j in T.grid(T.int64(4), T.int64(3)):
                with T.block("G"):
                    v_i, v_j = T.axis.remap("SS", [i, j])
                    T.reads()
                    T.writes(G[v_i, v_j])
                    T.block_attr({"schedule_rule":"None"})
                    G[v_i, v_j] = T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(3) == T.int64(2), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(3) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(3) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(3) == T.int64(2), T.float32(0.5), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(3) == T.int64(1), T.float32(0.5), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(3) == T.int64(0), T.float32(0.5), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(3) == T.int64(2), T.float32(0.5), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(3) == T.int64(1), T.float32(-0.5), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(3) == T.int64(0), T.float32(0.5), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(3) == T.int64(2), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(3) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(3) == T.int64(0), T.float32(1), T.float32(0)))))))))))))
            for eps_nu_co_ci_fused in T.thread_binding(T.int64(1024), thread="blockIdx.x"):
                for r_kh_r_kw_fused_0 in T.serial(T.int64(1)):
                    for r_kh_r_kw_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                        with T.block("transform_weight"):
                            T.where(r_kh_r_kw_fused_0 * T.int64(512) + r_kh_r_kw_fused_1 < T.int64(9))
                            v_eps = T.axis.spatial(T.int64(4), eps_nu_co_ci_fused // T.int64(256))
                            v_nu = T.axis.spatial(T.int64(4), eps_nu_co_ci_fused % T.int64(256) // T.int64(64))
                            v_co = T.axis.spatial(T.int64(8), eps_nu_co_ci_fused % T.int64(64) // T.int64(8))
                            v_ci = T.axis.spatial(T.int64(8), eps_nu_co_ci_fused % T.int64(8))
                            v_r_kh = T.axis.reduce(T.int64(3), (r_kh_r_kw_fused_0 * T.int64(512) + r_kh_r_kw_fused_1) // T.int64(3))
                            v_r_kw = T.axis.reduce(T.int64(3), (r_kh_r_kw_fused_0 * T.int64(512) + r_kh_r_kw_fused_1) % T.int64(3))
                            T.reads(p0[v_co, v_ci, v_r_kh, v_r_kw], G[T.min(v_eps, v_nu) : T.max(v_eps, v_nu) + T.int64(1), T.min(v_r_kh, v_r_kw) : T.max(v_r_kh, v_r_kw) + T.int64(1)])
                            T.writes(transform_weight[v_eps, v_nu, v_co, v_ci])
                            with T.init():
                                transform_weight[v_eps, v_nu, v_co, v_ci] = T.float32(0)
                            transform_weight[v_eps, v_nu, v_co, v_ci] = transform_weight[v_eps, v_nu, v_co, v_ci] + p0[v_co, v_ci, v_r_kh, v_r_kw] * G[v_eps, v_r_kh] * G[v_nu, v_r_kw]
    

b0 = sch.get_block(name="transform_weight", func_name="main")
b1 = sch.get_block(name="root", func_name="main")
v2 = sch.sample_categorical(candidates=[4, 8, 16, 32, 64, 128, 256, 512], probs=[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], decision=7)
l3, l4, l5, l6, l7, l8 = sch.get_loops(block=b0)
l9 = sch.fuse(l7, l8, preserve_unit_iters=True)
l10, l11 = sch.split(loop=l9, factors=[None, v2], preserve_unit_iters=True)
sch.bind(loop=l11, thread_axis="threadIdx.x")
v12 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.unroll_explicit", ann_val=v12)
l13, l14, l15, l16, l17, l18 = sch.get_loops(block=b0)
l19 = sch.fuse(l13, l14, l15, l16, preserve_unit_iters=True)
sch.bind(loop=l19, thread_axis="blockIdx.x")
2023-04-12 18:58:38 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-04-12 18:58:38 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2023-04-12 18:58:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564ef0269018)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564eecb64248)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564eef83a168)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564eed52d6e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564eef866878)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564ef0a6fe98)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564eefca3d28)]: 0 failure(s)
2023-04-12 18:58:39 [INFO] [evolutionary_search.cc:723] Sampled 512 candidate(s)
2023-04-12 18:58:39 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564ef0269018)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564eecb64248)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564eef83a168)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564eed52d6e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564eef866878)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564ef0a6fe98)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564eefca3d28)]: 0 failure(s)
2023-04-12 18:58:40 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564ef0269018)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564eecb64248)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564eef83a168)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564eed52d6e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564eef866878)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564ef0a6fe98)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564eefca3d28)]: 0 failure(s)
2023-04-12 18:58:40 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564ef0269018)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564eecb64248)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564eef83a168)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564eed52d6e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564eef866878)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564ef0a6fe98)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564eefca3d28)]: 0 failure(s)
2023-04-12 18:58:41 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x564ef0269018)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x564eecb64248)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x564eef83a168)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x564eed52d6e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x564eef866878)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x564ef0a6fe98)]: 0 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x564eefca3d28)]: 0 failure(s)
2023-04-12 18:58:41 [INFO] [evolutionary_search.cc:649] Scores of the best 10 candidates:
[1 : 10]:	0.9619  0.9517  0.9335  0.9178  0.8979  0.8906  0.8868  0.8777  0.8617  0.8328
2023-04-12 18:58:41 [INFO] [evolutionary_search.cc:727] Got 10 candidate(s) with evolutionary search
2023-04-12 18:58:41 [INFO] [evolutionary_search.cc:730] Sending 10 candidates(s) for measurement
2023-04-12 19:03:28 [INFO] [task_scheduler.cc:131] [Task #27: fused_nn_contrib_conv2d_winograd_weight_transform_2] Trial #1: GFLOPs: 5.2860. Time: 5.2304 us. Best GFLOPs: 5.2860
2023-04-12 19:03:28 [INFO] [task_scheduler.cc:131] [Task #27: fused_nn_contrib_conv2d_winograd_weight_transform_2] Trial #2: GFLOPs: 5.5537. Time: 4.9783 us. Best GFLOPs: 5.5537
2023-04-12 19:03:28 [INFO] [task_scheduler.cc:131] [Task #27: fused_nn_contrib_conv2d_winograd_weight_transform_2] Trial #3: GFLOPs: 4.6782. Time: 5.9100 us. Best GFLOPs: 5.5537
2023-04-12 19:03:28 [INFO] [task_scheduler.cc:131] [Task #27: fused_nn_contrib_conv2d_winograd_weight_transform_2] Trial #4: GFLOPs: 5.5410. Time: 4.9898 us. Best GFLOPs: 5.5537
2023-04-12 19:03:28 [INFO] [task_scheduler.cc:131] [Task #27: fused_nn_contrib_conv2d_winograd_weight_transform_2] Trial #5: GFLOPs: 5.5528. Time: 4.9791 us. Best GFLOPs: 5.5537
2023-04-12 19:03:28 [INFO] [task_scheduler.cc:131] [Task #27: fused_nn_contrib_conv2d_winograd_weight_transform_2] Trial #6: GFLOPs: 5.5529. Time: 4.9790 us. Best GFLOPs: 5.5537
2023-04-12 19:03:28 [INFO] [task_scheduler.cc:131] [Task #27: fused_nn_contrib_conv2d_winograd_weight_transform_2] Trial #7: GFLOPs: 5.5529. Time: 4.9790 us. Best GFLOPs: 5.5537
2023-04-12 19:03:28 [INFO] [task_scheduler.cc:131] [Task #27: fused_nn_contrib_conv2d_winograd_weight_transform_2] Trial #8: GFLOPs: 4.2292. Time: 6.5374 us. Best GFLOPs: 5.5537
2023-04-12 19:03:28 [INFO] [task_scheduler.cc:131] [Task #27: fused_nn_contrib_conv2d_winograd_weight_transform_2] Trial #9: GFLOPs: 5.3199. Time: 5.1971 us. Best GFLOPs: 5.5537
2023-04-12 19:03:28 [INFO] [task_scheduler.cc:131] [Task #27: fused_nn_contrib_conv2d_winograd_weight_transform_2] Trial #10: GFLOPs: 4.8727. Time: 5.6741 us. Best GFLOPs: 5.5537
